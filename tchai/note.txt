Trigram Size: 94628
Count male: 4959
Count female: 5041


10.000 records
Liblinear 2 seconds
62.16%

10.000 records
Libsvm 3 minutes 10 seconds
50.41%

==============================
Origin Size: 12923
Bigram Size: 370663
Trigram Size: 1230451
Total (male + female): 216872
Count male: 107702
Count female: 109170

Size original: 159 MB
Size Status: 31.1 MB
Size User: 17.0 MB

OS WINDOWN 7, Intel(R) Core(TM) i5-4590 CPU @ 3.30GHz (4CPUs), ~3.3GHz, Ram 16GB, HDD
trigram_tfidf.libsvm: 65.3 MB
Time: 14 minutes
==============================

Kết quả này sẽ phụ thuộc vào 3 yếu tốt
quan trọng hàng đầu đó là:
- Tập dữ liệu huấn luyện đủ lớn và chính xác. Trong quá trình huấn luyện, khi có
tập dữ liệu đủ lớn và chính xác thì quá trình huấn luyện sẽ tốt, đồng nghĩa với việc sẽ
có một mô hình phân lớp tốt phục vụ cho giai đoạn phân lớp sau này. Nếu như tập dữ
liệu quá ít thì sẽ gây ra tình trạng có nhiều đặc trưng chưa được “học” trong quá trình
huấn luyện. Và nếu tập dữ liệu không chính xác ngay từ đầu thì mô hình học dù có sử
dụng đúng phương pháp thì mô hình phân lớp cũng không thể tốt, dẫn dến hệ quả là
quá trình phân lớp sau này sẽ sai theo.
- Quá trình xử lý dữ liệu cũng là một bước quan trọng không kém. Có thể dễ dàng
nhận thấy một điều là các phương pháp ở trên hầu hết đều sử dụng mô hình vector để
biểu diễn văn bản. Do đó, việc lựa chọn phương pháp tách từ sẽ ảnh hưởng rất lớn đến
quá trình biểu diễn văn bản bằng vector. Đối với một số ngôn ngữ như tiếng Anh, việc
tách từ sẽ dễ dàng hơn vì các từ tách biệt nhau chỉ bởi dấu cách (khoảng trắng). Tuy
nhiên, đối với một số đa âm như tiếng Việt thì việc tách từ dựa trên khoảng trắng là
không chính xác, hơn nữa trong tiếng Việt có rất nhiều tính từ ở dạng từ ghép, loại từ
này chính là từ mang quan điểm nhiều nhất. Vậy nên việc lựa chọn phương pháp tách
từ là một yếu tố quan trọng quyết định đến độ chính xác cảu tập dữ liệu huấn luyện.
- Một thuật toán để sử dụng trong quá trình phân lớp (phân loại) sẽ là hợp lý khi
thuật toán phân loại có thời gian xử lý hợp lý. Tức là thời gian học, thời gian phân loại
văn bản là hợp lý. Bên cạnh đó, thuật toán cần phải có tính tăng cường (incremental
function), nghĩa là chỉ phân loại các văn bản mới mà không phân loại lại toàn bộ văn
bản khi thêm một số văn bản mới vào tập dữ liệu. Khi đó, thuật toán có khả năng giảm
độ nhiễu (noise) khi phân loại văn bản.

When to use LIBLINEAR but not LIBSVM

There are some large data for which with/without nonlinear mappings gives similar performances. Without using kernels, one can quickly train a much larger set via a linear classifier. Document classification is one such application. 
In the following example (20,242 instances and 47,236 features; available on LIBSVM data sets), the cross-validation time is significantly reduced by using LIBLINEAR:
Cross Validation Accuracy = 96.8136%, 345.569s

Cross Validation Accuracy = 97.0161%, 2.944s

Tạo sao Liblinear nhanh hơn Libsvm
Trong thực tế sự phức tạp của thuật toán SVM (kernel và linear SVM) được thực hiện trong Libsvm là O(n^2) hoặc O(n^3) trong khi đó liblinear là O(n) vì không hỗ trợ kernel. N là số lượng mẫu trong tập dữ liệu huấn luyện.
Liblinear được tối ưu hóa để đối phó với phân loại tuyến tính  (tức là không cần đến kernal-hạt nhân), trong khi phân loại tuyến tính chỉ là một trong nhiều khả năng của libsvm, do đó hợp lý nó có thể không phù hợp với liblinear về Độ chính xác phân loại

Usually, the decision is whether to use linear or an RBF (aka Gaussian) kernel. There are two main factors to consider:

Solving the optimisation problem for a linear kernel is much faster, see e.g. LIBLINEAR.
Typically, the best possible predictive performance is better for a nonlinear kernel (or at least as good as the linear one).
It's been shown that the linear kernel is a degenerate version of RBF, hence the linear kernel is never more accurate than a properly tuned RBF kernel. Quoting the abstract from the paper I linked:

    svm_type can be one of C_SVC, NU_SVC, ONE_CLASS, EPSILON_SVR, NU_SVR.

    C_SVC:		C-SVM classification
    NU_SVC:		nu-SVM classification
    ONE_CLASS:		one-class-SVM
    EPSILON_SVR:	epsilon-SVM regression
    NU_SVR:		nu-SVM regression

    kernel_type can be one of LINEAR, POLY, RBF, SIGMOID.

    LINEAR:	u'*v
    POLY:	(gamma*u'*v + coef0)^degree
    RBF:	exp(-gamma*|u-v|^2)
    SIGMOID:	tanh(gamma*u'*v + coef0)
    PRECOMPUTED: kernel values in training_set_file
	
Usage: train [options] training_set_file [model_file]
options:
-s type : set type of solver (default 1)
  for multi-class classification
	 0 -- L2-regularized logistic regression (primal)
	 1 -- L2-regularized L2-loss support vector classification (dual)
	 2 -- L2-regularized L2-loss support vector classification (primal)
	 3 -- L2-regularized L1-loss support vector classification (dual)
	 4 -- support vector classification by Crammer and Singer
	 5 -- L1-regularized L2-loss support vector classification
	 6 -- L1-regularized logistic regression
	 7 -- L2-regularized logistic regression (dual)
  for regression
	11 -- L2-regularized L2-loss support vector regression (primal)
	12 -- L2-regularized L2-loss support vector regression (dual)
	13 -- L2-regularized L1-loss support vector regression (dual)
-c cost : set the parameter C (default 1)
-p epsilon : set the epsilon in loss function of epsilon-SVR (default 0.1)
-e epsilon : set tolerance of termination criterion
	-s 0 and 2
		|f'(w)|_2 <= eps*min(pos,neg)/l*|f'(w0)|_2,
		where f is the primal function and pos/neg are # of
		positive/negative data (default 0.01)
	-s 11
		|f'(w)|_2 <= eps*|f'(w0)|_2 (default 0.001)
	-s 1, 3, 4 and 7
		Dual maximal violation <= eps; similar to libsvm (default 0.1)
	-s 5 and 6
		|f'(w)|_1 <= eps*min(pos,neg)/l*|f'(w0)|_1,
		where f is the primal function (default 0.01)
	-s 12 and 13\n"
		|f'(alpha)|_1 <= eps |f'(alpha0)|,
		where f is the dual function (default 0.1)
-B bias : if bias >= 0, instance x becomes [x; bias]; if < 0, no bias term added (default -1)
-wi weight: weights adjust the parameter C of different classes (see README for details)
-v n: n-fold cross validation mode
-C : find parameter C (only for -s 0 and 2)
-q : quiet mode (no outputs)

Option -v randomly splits the data into n parts and calculates cross
validation accuracy on them.

Option -C conducts cross validation under different C values and finds
the best one. This options is supported only by -s 0 and -s 2. If
the solver is not specified, -s 2 is used.

Mô hình Bag of Words (BoW) là một mô hình
được sử dụng phổ biến trong lĩnh vực phân loại
văn bản. Mô hình này thường sử dụng để xử lý
ngôn ngữ tự nhiên, được dùng để biểu diễn tài liệu,
xem tài liệu là một tập hợp các từ (words) mà
không quan tâm đến thứ tự cũng như cấu trúc cú
pháp của chúng.
Một văn bản được biểu diễn dạng véc-tơ (có n
thành phần là các từ tương ứng) mà giá trị thành
phần thứ j là tần số xuất hiện từ thứ j trong văn
bản. Nếu xét tập D gồm m văn bản và tự điển có n
từ vựng, thì D có thể được biểu diễn thành bảng D
kích thước m x n, dòng thứ i của bảng là véc-tơ
biểu diễn văn bản thứ i tương ứng.

Một số thuật toán thường được lựa chọn khi xây dựng bộ phân lớp gồm có: 
máy vector hỗ trợ (Support Vector Machine – SVM); 
k láng giềng gần nhất (K Nearest Neighbours – KNN); 
tiếp cận xác suất thống kê (Naïve Bayes – NB); 
Cây quyết định (Decision Tree – DT); 
sử dụng mạng nơron (Neural Network – Nnet); 
dựa trên vector trọng tâm (Centroid–base vector); 
hay tuyến tính bình phương nhỏ nhất (Linear Least Square Fit – LLSF)